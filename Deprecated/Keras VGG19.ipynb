{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7364 images belonging to 4 classes.\n",
      "Found 920 images belonging to 4 classes.\n",
      "Found 924 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Specify the input image size for VGG19\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Data Augmentation (commented out for comparison)\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=20,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "# )\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Specify the paths to your train, validation, and test data\n",
    "train_dir = 'D:\\\\Splitted Curated X-Ray Dataset\\\\train'\n",
    "val_dir = 'D:\\\\Splitted Curated X-Ray Dataset\\\\val'\n",
    "test_dir = 'D:\\\\Splitted Curated X-Ray Dataset\\\\test'\n",
    "\n",
    "# Flow training images in batches using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Flow validation images in batches using val_datagen generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "\n",
    ")\n",
    "\n",
    "# Flow test images in batches using test_datagen generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,448,196\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the VGG-19 model with pretrained weights (excluding the top dense layers)\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the VGG-19 base model\n",
    "model.add(base_model)\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a fully connected layer with 256 hidden units and ReLU activation\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add the final output layer with 4 classes for classification\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "230/230 [==============================] - 136s 585ms/step - loss: 0.5010 - accuracy: 0.7766 - val_loss: 0.4077 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "230/230 [==============================] - 133s 579ms/step - loss: 0.5065 - accuracy: 0.7691 - val_loss: 0.4157 - val_accuracy: 0.8449 - lr: 9.9593e-04\n",
      "Epoch 3/75\n",
      "230/230 [==============================] - 132s 574ms/step - loss: 0.4850 - accuracy: 0.7872 - val_loss: 0.3866 - val_accuracy: 0.8538 - lr: 9.9187e-04\n",
      "Epoch 4/75\n",
      "230/230 [==============================] - 132s 573ms/step - loss: 0.4636 - accuracy: 0.7912 - val_loss: 0.3793 - val_accuracy: 0.8616 - lr: 9.8783e-04\n",
      "Epoch 5/75\n",
      "230/230 [==============================] - 132s 572ms/step - loss: 0.4544 - accuracy: 0.7923 - val_loss: 0.3787 - val_accuracy: 0.8616 - lr: 9.8380e-04\n",
      "Epoch 6/75\n",
      "230/230 [==============================] - 133s 577ms/step - loss: 0.4420 - accuracy: 0.7964 - val_loss: 0.3753 - val_accuracy: 0.8627 - lr: 9.7980e-04\n",
      "Epoch 7/75\n",
      "230/230 [==============================] - 132s 572ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4220 - val_accuracy: 0.8482 - lr: 9.7580e-04\n",
      "Epoch 8/75\n",
      "230/230 [==============================] - 133s 576ms/step - loss: 0.4437 - accuracy: 0.7883 - val_loss: 0.3972 - val_accuracy: 0.8292 - lr: 9.7183e-04\n",
      "Epoch 9/75\n",
      "230/230 [==============================] - 132s 573ms/step - loss: 0.4540 - accuracy: 0.7852 - val_loss: 0.3739 - val_accuracy: 0.8616 - lr: 9.6787e-04\n",
      "Epoch 10/75\n",
      "230/230 [==============================] - 132s 572ms/step - loss: 0.4294 - accuracy: 0.8011 - val_loss: 0.3579 - val_accuracy: 0.8560 - lr: 9.6393e-04\n",
      "Epoch 11/75\n",
      "230/230 [==============================] - 132s 574ms/step - loss: 0.4388 - accuracy: 0.7908 - val_loss: 0.3768 - val_accuracy: 0.8538 - lr: 9.6000e-04\n",
      "Epoch 12/75\n",
      "230/230 [==============================] - 132s 573ms/step - loss: 0.4290 - accuracy: 0.7881 - val_loss: 0.3994 - val_accuracy: 0.8393 - lr: 9.5609e-04\n",
      "Epoch 13/75\n",
      "230/230 [==============================] - 132s 573ms/step - loss: 0.4418 - accuracy: 0.7845 - val_loss: 0.3972 - val_accuracy: 0.8527 - lr: 9.5219e-04\n",
      "Epoch 14/75\n",
      "230/230 [==============================] - 132s 572ms/step - loss: 0.4607 - accuracy: 0.7870 - val_loss: 0.4118 - val_accuracy: 0.8650 - lr: 9.4831e-04\n",
      "Epoch 15/75\n",
      "230/230 [==============================] - 132s 572ms/step - loss: 0.4364 - accuracy: 0.7945 - val_loss: 0.4087 - val_accuracy: 0.8661 - lr: 9.4445e-04\n",
      "924/924 [==============================] - 22s 23ms/step - loss: 0.3057 - accuracy: 0.8712\n",
      "Test Loss: 0.3057\n",
      "Test Accuracy: 0.8712\n"
     ]
    }
   ],
   "source": [
    "# Define the initial learning rate and the learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "# Define the optimizer with the learning rate schedule\n",
    "opt = optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define a custom learning rate scheduler function\n",
    "def custom_lr_schedule(epoch):\n",
    "    return initial_learning_rate * (0.96 ** (epoch / 10))\n",
    "\n",
    "# Set up LearningRateScheduler callback with the custom function\n",
    "lr_scheduler = LearningRateScheduler(custom_lr_schedule)\n",
    "\n",
    "# Train the model with the specified number of epochs\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=75,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    callbacks=[early_stop, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/924 [==============================] - 19s 20ms/step\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           COVID-19     0.9699    1.0000    0.9847       129\n",
      "             Normal     0.9758    0.9878    0.9818       327\n",
      "Pneumonia-Bacterial     0.7526    0.9502    0.8399       301\n",
      "    Pneumonia-Viral     0.8375    0.4012    0.5425       167\n",
      "\n",
      "           accuracy                         0.8712       924\n",
      "          macro avg     0.8840    0.8348    0.8372       924\n",
      "       weighted avg     0.8773    0.8712    0.8566       924\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = tf.argmax(y_pred, axis=1)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_labels, target_names=class_labels, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
